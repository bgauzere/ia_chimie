{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Trees, Random Forests and Ensemble Methods\n",
    "\n",
    "The purpose of this practical work is to implement differents methods based on Decision Trees. We will also focus on using a good protocol to evaluate our model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we will ensure that your configuration is ok. Run the following code to check if everything is running well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "#check du kernel name de ipykernel\n",
    "import ipykernel\n",
    "info= dict(eval(ipykernel.get_connection_info().replace(\"=\",\":\")))\n",
    "print(info[\"kernel_name\"])\n",
    "# devrait afficher ia_pour_la_chimie\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline \n",
    "\n",
    "# pour afficher les graphiques dans le notebook\n",
    "\n",
    "# Utility libraries\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple Decision Tree \n",
    "\n",
    "First, let's download a toy dataset to learn a decision tree, the iris dataset. Check the documentation to understand what it represent.\n",
    "\n",
    "1) using the default values provided by sklearn, learn a simple decision tree.\n",
    "2) explain the displayed figure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline \n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "correction"
    ]
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn import tree\n",
    "\n",
    "iris = load_iris()\n",
    "clf = tree.DecisionTreeClassifier()\n",
    "clf = clf.fit(iris.data, iris.target)\n",
    "tree.plot_tree(clf,label='all',filled=True,impurity=True);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "iris = ...\n",
    "clf = ...\n",
    "clf = clf...(iris.data, iris.target)\n",
    "tree.plot_tree(clf,label='all',filled=True,impurity=True);\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " 3) Change the max depth to 3. What do you expect ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "correction"
    ]
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn import tree\n",
    "\n",
    "iris = load_iris()\n",
    "clf = tree.DecisionTreeClassifier(max_depth=3)\n",
    "clf = clf.fit(iris.data, iris.target)\n",
    "tree.plot_tree(clf,label='all',filled=True,impurity=True);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "iris = load_iris()\n",
    "clf = DecisionTreeClassifier(...)\n",
    "clf = clf.fit(iris.data, iris.target)\n",
    "tree.plot_tree(clf,label='all',filled=True,impurity=True);\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we know how to learn a classifier, we will focus on the design  of a predictive model, by setting its hyperparameters in a proper way.\n",
    "\n",
    "1) Identify the hyperparameters to tune\n",
    "2) Identify a protocol to fit correctly the hyperparameters\n",
    "3) How do you measure the final performance of your model ?\n",
    "4) Implement the code to find an optimal value for each hyperparameter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "correction"
    ]
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.3,random_state=0)\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train,y_train,test_size=0.3,random_state=0)\n",
    "\n",
    "#parameters \n",
    "max_depth = [1,2,3,5,7]\n",
    "\n",
    "#grid search\n",
    "for i in max_depth:\n",
    "        clf = tree.DecisionTreeClassifier(max_depth=i,criterion='entropy')\n",
    "        clf = clf.fit(X_train, y_train)\n",
    "        ypred= clf.predict(X_val)\n",
    "        acc = accuracy_score(ypred,y_val)\n",
    "        acc_train = accuracy_score(y_train,clf.predict(X_train))\n",
    "        print(f\"max_depth: {i}, score val {acc:.2f}, score train {acc_train:.2f}\")\n",
    "\n",
    "print(f\"score final : {accuracy_score(y_test,clf.predict(X_test)):.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import ...\n",
    "from sklearn.metrics import accuracy_score\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "\n",
    "X_train, X_test, y_train, y_test = ...\n",
    "\n",
    "X_train, X_val, y_train, y_val = ...\n",
    "\n",
    "#parameters \n",
    "max_depth =  ...\n",
    "\n",
    "for i in max_depth:\n",
    "       ...\n",
    "\n",
    "clf = ...\n",
    "print(f\"score final : {accuracy_score(y_test,clf.predict(X_test)):.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To make your life easier, sklearn developpers develop the `GridSearchCV` class which mimics your previous code, but in a more efficient way\n",
    "\n",
    "1) Adapt your code to run the `GridSearchCV` and find the best hyperparameters\n",
    "2) What does `GridSearchCV` do ?\n",
    "3) Retrieve the validation accuracy of your `GridSearchCV`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.3,random_state=0)\n",
    "parameters = {...}\n",
    "clf = tree.DecisionTreeClassifier()\n",
    "cv = ...\n",
    "cv...\n",
    "print(f\"{cv.best_params_=}\")\n",
    "print(f\"{cv.best_score_=}, {cv.score.__name__ =}\")\n",
    "y_pred = ...\n",
    "print(f\"score final : {accuracy_score(y_test,y_pred):.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forests\n",
    "\n",
    "Now, we will enchance our model by implementing a Random Forest. To this end, let's use the `RandomForestClassifier` class of scikit-learn.\n",
    "\n",
    "1) Why not using `RandomForestRegressor` ?\n",
    "2) Retrieve the hyperparameter discussed in class in this implementation\n",
    "3) How is made the final decision ?\n",
    "4) Learn a simple RandomForest and give the performance on test set\n",
    "5) Define the hyperparameters values to be tuned\n",
    "6) Learn your model, and conclude. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "correction"
    ]
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score\n",
    "perf_test = []\n",
    "for _ in range(10):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.1,random_state=0)\n",
    "    parameters = { 'n_estimators':[10,50,100,200,500],\n",
    "                'max_depth':[None],\n",
    "                \"min_samples_split\":[2],\n",
    "                \"max_features\":[\"sqrt\",None]\n",
    "                }\n",
    "    clf = RandomForestClassifier()\n",
    "    cv = GridSearchCV(clf,parameters)\n",
    "    cv.fit(X_train,y_train)\n",
    "    print(f\"{cv.best_params_=}\")\n",
    "    print(f\"{cv.best_score_=:.2f}\")\n",
    "    perf_test.append(accuracy_score(y_test,cv.predict(X_test)))\n",
    "\n",
    "print(f\"score final : {np.mean(perf_test):.2f} +- {np.std(perf_test):.2f}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import ...\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score\n",
    "perf_test = []\n",
    "for _ in range(10):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.1,random_state=0)\n",
    "    parameters = {...}\n",
    "    clf = ...\n",
    "    cv = GridSearchCV(...)\n",
    "    cv.fit(X_train,y_train)\n",
    "    print(f\"{cv.best_params_=}\")\n",
    "    print(f\"{cv.best_score_=:.2f}\")\n",
    "    perf_test.append(accuracy_score(y_test,cv.predict(X_test)))\n",
    "\n",
    "print(f\"score final : {np.mean(perf_test):.2f} +- {np.std(perf_test):.2f}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Increasing the difficulty\n",
    "\n",
    "Now, we will focus on a chemical dataset, used in one of our research papers.\n",
    "\n",
    "This dataset is devoted to predict Mayr's experimental scale for electrophilicity. All electrophiles available in Mayr's Database (319 electrophiles) have been selected and then subjected to successive selections to finally obtain a database made of 111 molecules. Here the graph are described by 19 descriptors and each atom by 50 descriptors, including quantum chemical descriptors. To have more details on the chemical side, see with Vincent Tognetti.\n",
    "\n",
    "> Hoffmann, Guillaume, Muhammet Balcilar, Vincent Tognetti, Pierre Héroux, Benoit Beno\\^\\it Gaüzère, Sébastien Adam, et Laurent Joubert. 2020. « Predicting experimental electrophilicities from quantum and topological descriptors: A machine learning approach ». Journal of Computational Chemistry 41 (24): 2124‑36. https://doi.org/10.1002/jcc.26376.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets.cobra import CobraDataset\n",
    "\n",
    "data_Cobra = CobraDataset()\n",
    "X_cobra_graph = data_Cobra.graph_data\n",
    "X_cobra_atom = data_Cobra.atom_data\n",
    "X_cobra_graph_atom = data_Cobra.all_data\n",
    "y_cobra = data_Cobra.targets\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. What kind of problem is it ? (Check the values of y)\n",
    "2. Using a proper protol, compare the predictive power of the 3 set of descriptors\n",
    "3. Which one is the best ? What is your confidence ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "methods = [\n",
    "    {\"name\": \"Global inputs\", \"X\": X_cobra_graph},\n",
    "    {\"name\": \"Atom inputs\", \"X\": X_cobra_atom},\n",
    "    {\"name\": \"Combined inputs\",  \"X\": X_cobra_graph_atom}\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "correction"
    ]
   },
   "outputs": [],
   "source": [
    "\n",
    "def evaluate_model(X,y, model, parameters, splits):\n",
    "    \"\"\"\n",
    "    for regression\n",
    "    \"\"\"\n",
    "    mae_runs = []\n",
    "    cvs = []\n",
    "    y_pred = np.zeros(y.shape)\n",
    "    for (idx_train, idx_test) in tqdm(splits,leave=False):\n",
    "        cv = GridSearchCV(model,parameters,cv=10,scoring='neg_mean_absolute_error',n_jobs=-1)\n",
    "        cv.fit(X[idx_train, :], y[idx_train])\n",
    "        y_pred[idx_test] = cv.predict(X[idx_test,:])\n",
    "        cvs.append(cv)\n",
    "        \n",
    "    return y_pred, cvs\n",
    "\n",
    "# Parameters and Data for each method\n",
    "parameters = { 'n_estimators':[25,50,100,75, 150 ,200],\n",
    "            'max_depth':[None,3,5],\n",
    "            \"min_samples_split\":[2],\n",
    "            \"max_features\":[\"sqrt\",None]\n",
    "            }\n",
    "\n",
    "methods = [\n",
    "    {\"name\": \"Global inputs\", \"X\": X_cobra_graph},\n",
    "    {\"name\": \"Atom inputs\", \"X\": X_cobra_atom},\n",
    "    {\"name\": \"Combined inputs\",  \"X\": X_cobra_graph_atom}\n",
    "]\n",
    "n = X_cobra_graph.shape[0]\n",
    "\n",
    "#define model\n",
    "regressor = RandomForestRegressor()\n",
    "maes = {m['name']:[] for m in methods}\n",
    "\n",
    "for _ in tqdm(range(2)):\n",
    "    #define splits\n",
    "    kf = KFold(n_splits=10,shuffle=True)\n",
    "    splits = []\n",
    "    for idx_train, idx_test in kf.split(np.arange(n)):\n",
    "        splits.append((idx_train,idx_test))\n",
    "    for method in methods:\n",
    "        y_pred, cvs = evaluate_model(method[\"X\"], \n",
    "                                            y_cobra, \n",
    "                                            regressor,\n",
    "                                            parameters,\n",
    "                                            splits)\n",
    "        error = np.abs(y_cobra - y_pred)\n",
    "        maes[method[\"name\"]].append(np.mean(error))\n",
    "        print(f\"{method['name']}: Mean MAE = {np.mean(error):.2f}, Std MAE = {np.std(error):.2f}\")\n",
    "        print(cvs[-1].best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "correction"
    ]
   },
   "outputs": [],
   "source": [
    "for m in methods:\n",
    "    print(f\"{m['name']}: Mean MAE = {np.mean(maes[m['name']]):.2f}, Std MAE = {np.std(maes[m['name']]):.2f}\")\n",
    "               "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ensemble methods with Boosting\n",
    "\n",
    "Random forest are just one kind of ensemble methods based on trees. Others methods, more complex, have been proposed. Here, we will test two famous one : Gradient Boosting Decision Trees and Xgboost. These methods are the state of the art when dealing with tabular data.\n",
    "\n",
    "1) Implement a simple `GradientBoostingRegressor` from the scikit-learn library\n",
    "2) As usual, what hyperparameters will you focus on ? Do you understand them ?\n",
    "3) Find the best hyperparameters and compute the performance on test set.\n",
    "4) Do the same using the `XGBRegressor` from xgboost library. Comment on similar things."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "correction"
    ]
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "maes = {m['name']:[] for m in methods}\n",
    "parameters = { 'n_estimators':[25,50,100,75, 150 ,200],\n",
    "            'learning_rate':[1e-2,5e-2,1e-1,.5],\n",
    "            }\n",
    "regressor = GradientBoostingRegressor()\n",
    "\n",
    "for _ in tqdm(range(1)):\n",
    "    #define splits\n",
    "    kf = KFold(n_splits=10,shuffle=True)\n",
    "    splits = []\n",
    "    for idx_train, idx_test in kf.split(np.arange(n)):\n",
    "        splits.append((idx_train,idx_test))\n",
    "    for method in methods:\n",
    "        y_pred, cvs = evaluate_model(method[\"X\"], \n",
    "                                            y_cobra, \n",
    "                                            regressor,\n",
    "                                            parameters,\n",
    "                                            splits)\n",
    "        error = np.abs(y_cobra - y_pred)\n",
    "        maes[method[\"name\"]].append(np.mean(error))\n",
    "        print(f\"{method['name']}: Mean MAE = {np.mean(error):.2f}, Std MAE = {np.std(error):.2f}\")\n",
    "        \n",
    "for m in methods:\n",
    "    print(f\"{m['name']}: Mean MAE = {np.mean(maes[m['name']]):.2f}, Std MAE = {np.std(maes[m['name']]):.2f}\")\n",
    "               "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import ...\n",
    "\n",
    "parameters = {...}\n",
    "regressor = ...\n",
    "\n",
    "maes = {m['name']:[] for m in methods}\n",
    "...\n",
    "#Résultats\n",
    "for m in methods:\n",
    "    print(f\"{m['name']}: Mean MAE = {np.mean(maes[m['name']]):.2f}, Std MAE = {np.std(maes[m['name']]):.2f}\")\n",
    "               "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "correction"
    ]
   },
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "\n",
    "## Protocole à factoriser !\n",
    "maes = {m['name']:[] for m in methods}\n",
    "parameters = { 'n_estimators':[25,50,100,75, 150 ,200],\n",
    "            'learning_rate':[1e-2,5e-2,1e-1,.5]\n",
    "            }\n",
    "regressor = model = xgb.XGBRegressor()\n",
    "\n",
    "for _ in tqdm(range(1)):\n",
    "    #define splits\n",
    "    kf = KFold(n_splits=10,shuffle=True)\n",
    "    splits = []\n",
    "    for idx_train, idx_test in kf.split(np.arange(n)):\n",
    "        splits.append((idx_train,idx_test))\n",
    "    for method in methods:\n",
    "        y_pred, cvs = evaluate_model(method[\"X\"], \n",
    "                                    y_cobra, \n",
    "                                    regressor,\n",
    "                                    parameters,\n",
    "                                    splits)\n",
    "        error = np.abs(y_cobra - y_pred)\n",
    "        maes[method[\"name\"]].append(np.mean(error))\n",
    "        print(f\"{method['name']}: Mean MAE = {np.mean(error):.2f}, Std MAE = {np.std(error):.2f}\")\n",
    "        print(cvs[-1].best_params_)\n",
    "for m in methods:\n",
    "    print(f\"{m['name']}: Mean MAE = {np.mean(maes[m['name']]):.2f}, Std MAE = {np.std(maes[m['name']]):.2f}\")\n",
    "               \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "\n",
    "## \n",
    "## Same thing with Xgboost !\n",
    "maes = {m['name']:[] for m in methods}\n",
    "parameters = { ...}\n",
    "regressor = ...\n",
    "\n",
    "# A completer \n",
    "for m in methods:\n",
    "    print(f\"{m['name']}: Mean MAE = {np.mean(maes[m['name']]):.2f}, Std MAE = {np.std(maes[m['name']]):.2f}\")\n",
    "               \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ia_pour_la_chimie",
   "language": "python",
   "name": "ia_pour_la_chimie"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
